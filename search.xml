<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>哈密顿神经网络</title>
      <link href="/2022/12/06/ha-mi-dun-shen-jing-wang-luo/"/>
      <url>/2022/12/06/ha-mi-dun-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="哈密顿神经网络"><a href="#哈密顿神经网络" class="headerlink" title="哈密顿神经网络"></a>哈密顿神经网络</h1><p>意图让通过调整神经网络架构让网络包含哈密顿量的某些性质，从而提高从数据中学习哈密顿量的效果。</p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h3 id="哈密顿方程"><a href="#哈密顿方程" class="headerlink" title="哈密顿方程:"></a>哈密顿方程:</h3><p>$\dot{p}<em>\alpha=\frac{\partial H}{\partial q</em>\alpha},\dot{q}<em>\alpha=-\frac{\partial H}{\partial p</em>\alpha}$ ，$\alpha$为指标</p><p>用动量$p$和位置$q$足以描述一个系统的所有状态，故知道了一个系统的哈密顿量$H$就可以通过哈密顿方程得到这个系统演化的所有信息。</p><h3 id="相空间"><a href="#相空间" class="headerlink" title="相空间"></a>相空间</h3><p>相空间 $(\vec{q},\vec{p})$中的一点记录了组成某个系统的所有粒子的位置和动量，包含了这个系统这个状态下的全部信息。</p><p>要想知道一个系统随时间演化的过程，需要知道</p><script type="math/tex; mode=display">\frac{dp}{dt}= \dot{p},\frac{dq}{dt}=\dot{q}</script><p>由哈密顿方程可知，这正是哈密顿量$H$在相空间的辛梯度（symplectic gradient).</p><script type="math/tex; mode=display">S_H=(\frac{\partial H}{\partial p},-\frac{\partial H}{\partial q})</script><p>有了初状态($q_0,p_0$)后，可以很方便的得到系统演化过程中任一状态</p><script type="math/tex; mode=display">(q_1,p_1)=(q_0,p_0)+\int_{t_0}^{t_1}S_H(q,p)dt</script><p>可以用数值手段做到这件事，比如range-kutta积分（RK4），追求保辛结构可以用verlet积分。</p><h2 id="HNN"><a href="#HNN" class="headerlink" title="HNN"></a>HNN</h2><p>$S<em>H$是我们想要的东西，但HNN不直接训练$S_H$,而是训练一个哈密顿量$H$。输入($q,p$),输出一个标量，$H</em>{\theta}$.训练时也不直接训练这个标量$H_{\theta}$，而是训练它的辛梯度。</p><script type="math/tex; mode=display">\mathcal{L}_{HNN}=\vert\vert \frac{\partial H_{\theta}}{\partial p}- \frac{\partial q}{\partial t}\vert\vert_2+\vert\vert \frac{\partial H_{\theta}}{\partial q}- \frac{\partial p}{\partial t}\vert\vert_2</script><p>就是说参数化以($q,p$)为变量的哈密顿量，训练时也把($\dot{q},\dot{p}$)作为ground truth ,用 auto grad 去算$H_{\theta}$的辛梯度，优化它们之间的$L_2$损失。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>对于最简单的谐振子可以直接写出它的哈密顿量：</p><script type="math/tex; mode=display">H=p^2+q^2</script><p>可以知道对于任意一个初状态，之后的状态都落在圆轨迹上，训练数据就利用$H$，在不同的轨迹上采样，得到($q,p,\dot{p},\dot{q},t$),事实上时间$t$在训练过程中是不必要的，是之后分析会用到的。($q,p$)作为data，($\dot{q},\dot{p}$)作为label。在训练时可以在data上加上噪声。</p><p>$h_{t+1}=h_t+f(h_t,\theta_t)$</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>五种经典神经网络</title>
      <link href="/2022/12/03/wu-chong-jing-dian-shen-jing-wang-luo/"/>
      <url>/2022/12/03/wu-chong-jing-dian-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="五种典型神经网络结构"><a href="#五种典型神经网络结构" class="headerlink" title="五种典型神经网络结构"></a>五种典型神经网络结构</h1><p>==Lenet,AlexNet,VGGNet,InceptionNet,ResNet==</p><h2 id="LeNet-1998"><a href="#LeNet-1998" class="headerlink" title="LeNet-1998"></a>LeNet-1998</h2><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>./五种经典神经网络.assets/image-20221203115415533.png<span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>48<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="五种经典神经网络.assets/image-20221203115415533.png" alt="image-20221203115415533"><img></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token operator">=</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="AlexNet-2012"><a href="#AlexNet-2012" class="headerlink" title="AlexNet-2012"></a>AlexNet-2012</h2><p><img src="五种经典神经网络.assets/image-20221203122322855.png" alt="image-20221203122322855"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token operator">=</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">96</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="VGGNet-2014"><a href="#VGGNet-2014" class="headerlink" title="VGGNet-2014"></a>VGGNet-2014</h2><p>适合硬件加速</p><p><img src="五种经典神经网络.assets/image-20221203125136731.png" alt="image-20221203125136731"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span>models<span class="token punctuation">,</span>optimizers<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token operator">=</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>x_train<span class="token punctuation">,</span>x_test<span class="token operator">=</span>x_train<span class="token operator">/</span><span class="token number">255.0</span><span class="token punctuation">,</span>x_test<span class="token operator">/</span><span class="token number">255.0</span>x_train<span class="token operator">=</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>x_test<span class="token operator">=</span>tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#%%</span>model<span class="token operator">=</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#%%</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>    optimizer<span class="token operator">=</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sparse_categorical_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> validation_freq<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="InceptionNet-2014"><a href="#InceptionNet-2014" class="headerlink" title="InceptionNet-2014"></a>InceptionNet-2014</h2><p><img src="五种经典神经网络.assets/image-20221203133706817.png" alt="核心Inception块"></p><p><img src="五种经典神经网络.assets/image-20221203140117732.png" alt="image-20221203140117732"></p><p><img src="五种经典神经网络.assets/image-20221203140217546.png" alt="image-20221203140217546"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> models<span class="token punctuation">,</span> optimizers<span class="token keyword">import</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<span class="token keyword">from</span> keras <span class="token keyword">import</span> Model<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> x_test <span class="token operator">/</span> <span class="token number">255.0</span>x_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>x_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># %%</span><span class="token keyword">class</span> <span class="token class-name">ConBNRelu</span><span class="token punctuation">(</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ConBNRelu<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>            layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">)</span><span class="token punctuation">,</span>            layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">InceptionBlk</span><span class="token punctuation">(</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ch<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>InceptionBlk<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ch <span class="token operator">=</span> ch        self<span class="token punctuation">.</span>strides <span class="token operator">=</span> strides        self<span class="token punctuation">.</span>c1 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c2_1 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c2_2 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c3_1 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c3_2 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p4_1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c4_2 <span class="token operator">=</span> ConBNRelu<span class="token punctuation">(</span>ch<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>c1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x2_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>c2_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x2_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>c2_2<span class="token punctuation">(</span>x2_1<span class="token punctuation">)</span>        x3_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>c3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x3_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>c3_2<span class="token punctuation">(</span>x3_1<span class="token punctuation">)</span>        x4_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>p4_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x4_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>c4_2<span class="token punctuation">(</span>x4_1<span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>x1<span class="token punctuation">,</span> x2_2<span class="token punctuation">,</span> x3_2<span class="token punctuation">,</span> x4_2<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token keyword">class</span> <span class="token class-name">Inception10</span><span class="token punctuation">(</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_blocks<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> init_ch<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Inception10<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_channels<span class="token operator">=</span>init_ch        self<span class="token punctuation">.</span>out_channels<span class="token operator">=</span>init_ch        self<span class="token punctuation">.</span>num_blocks<span class="token operator">=</span>num_blocks        self<span class="token punctuation">.</span>init_ch<span class="token operator">=</span>init_ch        self<span class="token punctuation">.</span>c1<span class="token operator">=</span>ConBNRelu<span class="token punctuation">(</span>init_ch<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>blocks<span class="token operator">=</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> block_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_blocks<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> layer_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> layer_id<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>                    block<span class="token operator">=</span>InceptionBlk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    block<span class="token operator">=</span>InceptionBlk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>blocks<span class="token punctuation">.</span>add<span class="token punctuation">(</span>block<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>out_channels <span class="token operator">*=</span><span class="token number">2</span>        self<span class="token punctuation">.</span>p1<span class="token operator">=</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>f1<span class="token operator">=</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>c1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x<span class="token operator">=</span>self<span class="token punctuation">.</span>p1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y<span class="token operator">=</span>self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> ymodel<span class="token operator">=</span>Inception10<span class="token punctuation">(</span>num_blocks<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>    optimizer<span class="token operator">=</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sparse_categorical_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> validation_freq<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="ResNet-2015"><a href="#ResNet-2015" class="headerlink" title="ResNet-2015"></a>ResNet-2015</h2><p><img src="五种经典神经网络.assets/image-20221203141829459.png" alt="image-20221203141829459"></p><p><img src="五种经典神经网络.assets/image-20221203142037743.png" alt="image-20221203142037743"></p><p><img src="五种经典神经网络.assets/image-20221203142240847.png" alt="image-20221203142240847"></p><p><img src="五种经典神经网络.assets/image-20221203142349389.png" alt="image-20221203142349389"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">import</span> os<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv2D<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> MaxPool2D<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dense<span class="token keyword">from</span> keras <span class="token keyword">import</span> Modelnp<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>threshold<span class="token operator">=</span>np<span class="token punctuation">.</span>inf<span class="token punctuation">)</span>cifar10 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>cifar10<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> cifar10<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> x_test <span class="token operator">/</span> <span class="token number">255.0</span><span class="token keyword">class</span> <span class="token class-name">ResnetBlock</span><span class="token punctuation">(</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> residual_path<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ResnetBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>filters <span class="token operator">=</span> filters        self<span class="token punctuation">.</span>strides <span class="token operator">=</span> strides        self<span class="token punctuation">.</span>residual_path <span class="token operator">=</span> residual_path        self<span class="token punctuation">.</span>c1 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b1 <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>a1 <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>c2 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b2 <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># residual_path为True时，对输入进行下采样，即用1x1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加</span>        <span class="token keyword">if</span> residual_path<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>down_c1 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>filters<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span>strides<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>down_b1 <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>a2 <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        residual <span class="token operator">=</span> inputs  <span class="token comment"># residual等于输入值本身，即residual=x</span>        <span class="token comment"># 将输入通过卷积、BN层、激活层，计算F(x)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>c1<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>b1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>a1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>c2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>b2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>residual_path<span class="token punctuation">:</span>            residual <span class="token operator">=</span> self<span class="token punctuation">.</span>down_c1<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>            residual <span class="token operator">=</span> self<span class="token punctuation">.</span>down_b1<span class="token punctuation">(</span>residual<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>a2<span class="token punctuation">(</span>y <span class="token operator">+</span> residual<span class="token punctuation">)</span>  <span class="token comment"># 最后输出的是两部分的和，即F(x)+x或F(x)+Wx,再过激活函数</span>        <span class="token keyword">return</span> out<span class="token keyword">class</span> <span class="token class-name">ResNet18</span><span class="token punctuation">(</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> block_list<span class="token punctuation">,</span> initial_filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># block_list表示每个block有几个卷积层</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>ResNet18<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_blocks <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>block_list<span class="token punctuation">)</span>  <span class="token comment"># 共有几个block</span>        self<span class="token punctuation">.</span>block_list <span class="token operator">=</span> block_list        self<span class="token punctuation">.</span>out_filters <span class="token operator">=</span> initial_filters        self<span class="token punctuation">.</span>c1 <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_filters<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>b1 <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>a1 <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>blocks <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 构建ResNet网络结构</span>        <span class="token keyword">for</span> block_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>block_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 第几个resnet block</span>            <span class="token keyword">for</span> layer_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>block_list<span class="token punctuation">[</span>block_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 第几个卷积层</span>                <span class="token keyword">if</span> block_id <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">and</span> layer_id <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment"># 对除第一个block以外的每个block的输入进行下采样</span>                    block <span class="token operator">=</span> ResnetBlock<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_filters<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> residual_path<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    block <span class="token operator">=</span> ResnetBlock<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_filters<span class="token punctuation">,</span> residual_path<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>blocks<span class="token punctuation">.</span>add<span class="token punctuation">(</span>block<span class="token punctuation">)</span>  <span class="token comment"># 将构建好的block加入resnet</span>            self<span class="token punctuation">.</span>out_filters <span class="token operator">*=</span> <span class="token number">2</span>  <span class="token comment"># 下一个block的卷积核数是上一个block的2倍</span>        self<span class="token punctuation">.</span>p1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>f1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">,</span> kernel_regularizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>l2<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>c1<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>b1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>a1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>blocks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>p1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> ymodel <span class="token operator">=</span> ResNet18<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>              loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sparse_categorical_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>checkpoint_save_path <span class="token operator">=</span> <span class="token string">"./checkpoint/ResNet18.ckpt"</span><span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>checkpoint_save_path <span class="token operator">+</span> <span class="token string">'.index'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------------load the model-----------------'</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>load_weights<span class="token punctuation">(</span>checkpoint_save_path<span class="token punctuation">)</span>cp_callback <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>ModelCheckpoint<span class="token punctuation">(</span>filepath<span class="token operator">=</span>checkpoint_save_path<span class="token punctuation">,</span>                                                 save_weights_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                                 save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> validation_freq<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>cp_callback<span class="token punctuation">]</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="五种经典神经网络.assets/image-20221203143357501.png" alt="image-20221203143357501"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>毕业论文整理</title>
      <link href="/2022/11/23/bi-ye-lun-wen-zheng-li/"/>
      <url>/2022/11/23/bi-ye-lun-wen-zheng-li/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Accelerating-Neural-ODEs-Using-Model-Order-Reduction"><a href="#1-Accelerating-Neural-ODEs-Using-Model-Order-Reduction" class="headerlink" title="1. Accelerating Neural ODEs Using Model Order Reduction"></a>1. Accelerating Neural ODEs Using Model Order Reduction</h2><p>本篇主要是想利用MOR方法来加速Neura ODE 。</p><p>关于压缩并加速Neural ODE目前只用到了以下三种方法：</p><ol><li>POD-DEIM</li><li>SVD based truncation</li><li>APoZ method</li></ol><h2 id="2-Model-Order-Reduction-for-Networks-of-ODE-and-PDE-Systems"><a href="#2-Model-Order-Reduction-for-Networks-of-ODE-and-PDE-Systems" class="headerlink" title="2. Model Order Reduction for Networks of ODE and PDE Systems"></a>2. Model Order Reduction for Networks of ODE and PDE Systems</h2><h2 id="3-Model-Order-Reduction"><a href="#3-Model-Order-Reduction" class="headerlink" title="3. Model Order Reduction"></a>3. Model Order Reduction</h2><p>介绍了Model Order Reduction，主要介绍了POD，PGD和RBM</p><h2 id="4-Modelling-Dynamical-Systems-Using-Neural-Ordinary-Differential-Equations"><a href="#4-Modelling-Dynamical-Systems-Using-Neural-Ordinary-Differential-Equations" class="headerlink" title="4. Modelling Dynamical Systems Using Neural Ordinary Differential Equations"></a>4. Modelling Dynamical Systems Using Neural Ordinary Differential Equations</h2><p>利用神经网络从数据中学习ODE，本文的目的将ODEnets作为一种建模工具来从数据中直接学得动力学行为。</p><h2 id="5-Model-Order-Reduction-for-Nonlinear-Systems"><a href="#5-Model-Order-Reduction-for-Nonlinear-Systems" class="headerlink" title="5. Model Order Reduction for Nonlinear Systems"></a>5. Model Order Reduction for Nonlinear Systems</h2><p>什么是MOR；对于非线性系统的MOR，以及非线性系统的二次化简；Reduce 非线性系统的奇遇方法。</p><h2 id="6-Neural-Ordinary-Differential-Equations-for-Data-Driven-Reduced-Order-Modeling-of-Environmental-Hydrodynamics"><a href="#6-Neural-Ordinary-Differential-Equations-for-Data-Driven-Reduced-Order-Modeling-of-Environmental-Hydrodynamics" class="headerlink" title="6. Neural Ordinary Differential Equations for Data-Driven Reduced Order Modeling of Environmental Hydrodynamics"></a>6. Neural Ordinary Differential Equations for Data-Driven Reduced Order Modeling of Environmental Hydrodynamics</h2><p>将neural ODE作为一种在降阶模型中传播潜在空间动力学。</p><h2 id="7-On-Neural-Differential-Equations"><a href="#7-On-Neural-Differential-Equations" class="headerlink" title="7. On Neural Differential Equations"></a>7. On Neural Differential Equations</h2><p>介绍了微分方程与神经网络结合的相关知识</p><h2 id="8-Hamiltonian-Neural-Networks"><a href="#8-Hamiltonian-Neural-Networks" class="headerlink" title="8.Hamiltonian Neural Networks"></a>8.Hamiltonian Neural Networks</h2><p>从哈密顿结构中获得信息，从而赋予神经网络更好的归纳偏好，提高神经网络效率。</p><h2 id="9-On-Second-Order-Behaviour-in-Augmented-Neural-ODEs"><a href="#9-On-Second-Order-Behaviour-in-Augmented-Neural-ODEs" class="headerlink" title="9.On Second Order Behaviour in Augmented Neural ODEs"></a>9.On Second Order Behaviour in Augmented Neural ODEs</h2><p>介绍了二阶的Augmented Neural ODEs的相关性质</p><h2 id="10-Parameterized-Neural-Ordinary-Differential-Equations-Applications-to-Computational-Physics-Problems"><a href="#10-Parameterized-Neural-Ordinary-Differential-Equations-Applications-to-Computational-Physics-Problems" class="headerlink" title="10.Parameterized Neural Ordinary Differential Equations: Applications to Computational Physics Problems"></a>10.Parameterized Neural Ordinary Differential Equations: Applications to Computational Physics Problems</h2><p>参数化neural ODE，并将参数化neuralODE作为一种降维模型来研究物理问题</p><h2 id="11-Reduced-order-Model-for-Fluid-Flows-via-Neural-Ordinary-Differential-Equations"><a href="#11-Reduced-order-Model-for-Fluid-Flows-via-Neural-Ordinary-Differential-Equations" class="headerlink" title="11.Reduced-order Model for Fluid Flows via Neural Ordinary Differential Equations"></a>11.Reduced-order Model for Fluid Flows via Neural Ordinary Differential Equations</h2><p>用POD来减少模型的维度，用neural ODE来预测模型的时间系数的行为，从而取代了经典的Galerkin projection.</p><h2 id="12-Symplectic-Neural-Networks-in-Taylor-Series-Form-for-Hamiltonian-Systems"><a href="#12-Symplectic-Neural-Networks-in-Taylor-Series-Form-for-Hamiltonian-Systems" class="headerlink" title="12.Symplectic Neural Networks in Taylor Series Form for Hamiltonian Systems"></a>12.Symplectic Neural Networks in Taylor Series Form for Hamiltonian Systems</h2><p>引入一个四阶辛积分器将神经ode的框架结合到Taylor-net架构中,同时学习目标系统的连续时间演化保持它们的辛结构</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>微分方程与机器学习</title>
      <link href="/2022/11/20/wei-fen-fang-cheng-yu-ji-qi-xue-xi-de-guan-xi/"/>
      <url>/2022/11/20/wei-fen-fang-cheng-yu-ji-qi-xue-xi-de-guan-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="微分方程与机器学习之间的关系"><a href="#微分方程与机器学习之间的关系" class="headerlink" title="微分方程与机器学习之间的关系"></a>微分方程与机器学习之间的关系</h1><p> A differential equation is a way to specify an arbitrary nonlinear transform by mathematically encoding prior structural assumptions.</p><p>我们知道，一个非线性变换可以有三种定义方式：1.直接建模；2.机器学习；3.微分方程。</p><p>1.直接建模：当你知道关于输入到输出之间的确切的表达时，那就可以直接写出函数形式。</p><p>但实际情况是，大部分你都不会知道输入与输出之间的确切表达，那这时候应该如何构建非线性变换呢？</p><p>这时我们就可以采用机器学习的方式来构建。例如我们采用使用sigmoid函数来作为激活函数，且只有三层的深度神经网络来构建非线性变换，假设输入为：$x$,输出为：$y$，则：</p><script type="math/tex; mode=display">y=\sigma(W_3 \cdot \sigma(W_2 \cdot \sigma(W_1 \cdot x))) \tag{1}</script><p>其中$W=(W_1,W_2,W_3)$为可学习参数，可以通过选择$W$使得$y$能尽可能的拟合你想要它去拟合的函数。因为随着层数的增多，$y$几乎可以逼近任何非线性函数。</p><p>以微分方程构建非线性变换就是说问题能用微分方程的形式表现出来。例如我们考虑这个问题——研究某片森林中兔子的数量，我们知道出生率依赖于当前兔子的数量，那我们就可以简单假设这种依赖关系为：</p><script type="math/tex; mode=display">rabbits'(t)=\alpha \cdot rabbits(t)</script><p>其中 $\alpha$为学习常数。一般情况下是解不出来的，只不过这里可以计算出来$rabbits(t)=rabbits(t_{start})e^{\alpha t}$</p><p>由此可以看出，微分方程的构建其实是来源于我们现在已知的的关于问题的一些知识，常常都是从物理、生物、化学等方面获得。</p><p><strong>那么我们就要想想，能不能将微分方程（已有的信息）与机器学习（学习隐藏的信息）结合起来呢？</strong></p><h1 id="Neural-ODE"><a href="#Neural-ODE" class="headerlink" title="Neural ODE"></a>Neural ODE</h1><p>2018年<strong>Alexandr Honchar</strong>发表了<strong>Neural ODEs: breakdown of another deep learning breakthrough</strong>就是将常微分方程与神经网络结合起来。论文的简要概括就是：希望通过学习非线性变换的结构来代替直接学习非线性变换，换句话说就是将学习目标：$y=ML(x)$换成$y’(x)=ML(x)$，然后解这个ODE。如果我们采用the Euler method来解，即：</p><script type="math/tex; mode=display">\Delta y=(y_{next}-y_{prev})=\Delta x \cdot ML(x)</script><p>推出：$y_{i+1}=y_i+\Delta x \cdot ML(x_i)$会发现它等价于一个a <strong>residual neural network</strong>(<a href="https://arxiv.org/abs/1512.03385)。并且会发现随着残差网络中每一层趋于零，网络越来越深，最后就像一个无限深度的model。为了避免这种情况，我们直接通过一种特定的ODE">https://arxiv.org/abs/1512.03385)。并且会发现随着残差网络中每一层趋于零，网络越来越深，最后就像一个无限深度的model。为了避免这种情况，我们直接通过一种特定的ODE</a> solver来求解这个微分方程。一般都采用Julia来求解。<a href="https://www.youtube.com/watch?v=KPEqYtEd-zY">video tutorial on solving ODEs in Julia</a></p><p>说了这么多，那么<strong>怎么将一个ODE嵌入到神经网络中去呢？</strong></p><p>首先我们要理解一个神经网络中的一层(layer)是什么，A layer 其实就是一个将n 维向量映成m 维向量的微分函数。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Lanczos方法-数值计算</title>
      <link href="/2022/11/17/te-zheng-zhi-wen-ti-lanczos-fang-fa/"/>
      <url>/2022/11/17/te-zheng-zhi-wen-ti-lanczos-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="特征值问题-Lanczos方法"><a href="#特征值问题-Lanczos方法" class="headerlink" title="特征值问题-Lanczos方法"></a>特征值问题-Lanczos方法</h1><h2 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h2><p>寻找矩阵的特征多项式，以求得其特征值。lanczos方法主要是针对求大型稀疏矩阵的特征值。</p><h2 id="一-Lanczos方法-也叫最小迭代法"><a href="#一-Lanczos方法-也叫最小迭代法" class="headerlink" title="一.Lanczos方法(也叫最小迭代法)"></a>一.Lanczos方法(也叫最小迭代法)</h2><h3 id="1-对于对称矩阵-A’-A"><a href="#1-对于对称矩阵-A’-A" class="headerlink" title="1.对于对称矩阵$A’=A$"></a>1.对于对称矩阵$A’=A$</h3><p>求解特征多项式方程$G(\mu)=det(A-\mu I)=0$,即解$Aw=\mu w$其中$w$称为特征向量，而$\mu$是其相应的特征值。</p><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h4><p>通过生成一系列的尝试向量，来生成一组前后依次相关的多项式。</p><h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><ol><li>先随机选取一个向量$b_0$，下一个新的向量$b_1$是选一个$b_0$和$Ab_0$的线性组合</li></ol><script type="math/tex; mode=display">b_1=Ab_0-\alpha_0 b_0.</script><p>其中$\alpha_0=argminb_1^2=argmin(Ab_0-\alpha_0 b_0)^2$,$故\alpha_0=\frac{(Ab_0)’b_0}{b_0’b_0}$</p><p>由此选取的$b_1和\alpha_0$满足：$b_1’b_0=0$,$即b_1与b_0$正交。从这里可以看出正交性与$\alpha_0=argminb_1^2$是等价的！</p><ol><li>继续这个过程，选取线性组合</li></ol><script type="math/tex; mode=display">b_2=Ab_1-\alpha_1b_1-\beta_0b_0,</script><p>其中$\alpha_1,\beta_0=argminb_2’b_2=argmin(Ab_1-\alpha_1 b_1-\beta_0 b_0)’(Ab_1-\alpha_1 b_1-\beta_0 b_0)$,</p><p>故$\alpha_1=\frac{(Ab_1)’b_1}{b_1’b_1},\beta_0=\frac{(Ab_1)’b_0}{b_0’b_0}$</p><p>由此选取的$b_1,\alpha_0与\beta_0$满足：$b_2同时正交b_0和b_1.$</p><ol><li>再继续这个过程，需要计算</li></ol><script type="math/tex; mode=display">b_3=Ab_2-\alpha_2b_2-\beta_1b_1-\gamma_0b_0.</script><p>要满足$b_3$与$b_2,b_1,b_0$均正交，则取：</p><script type="math/tex; mode=display">\alpha_2=\frac{b_2'Ab_2}{b_2'b_2},\beta_1=\frac{b_1'Ab_2}{b_1'b_1},\gamma_0=\frac{b_2'Ab_0}{b_0'b_0}=\frac{b_2'(b_1+\alpha_0b_0)}{b_0'b_0}=0</script><p>Lanczos发现，每一步迭代只需要两个修正项，即著名的三项递归式，其步骤如下：</p><script type="math/tex; mode=display">b_1=(A-\alpha_0 I)b_0,\\b_2=(A-\alpha_1 I)b_1-\beta_0b_0,\\b_3=(A-\alpha_2 I)b_2-\beta_1b_1,\\...\\b_m=(A-\alpha_{m-1} I)b_{m-1}-\beta_{m-2}b_{m-2}=0</script><p>当出现第$m$次递归式等于零时停止。Lanczos认为此事达到了最小多项式的秩，这里$n\geq m$,$n$是对称矩阵$A$的阶。但是，在有限精度运算的情况下，这一过程可能在得到最小多项式的秩之前，$\beta_k$就已经非常小了，且$k&lt;m$.在20 世纪 60 年代, 由于人们没有对这一现象充分地理解, 致使当时 Lanczos 方法在数值计算领域上没有太大的进展.</p><h3 id="2-非对称矩阵"><a href="#2-非对称矩阵" class="headerlink" title="2.非对称矩阵"></a>2.非对称矩阵</h3><h4 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h4><p>同时对矩阵$A$和其转置矩阵$A’$执行上述过程，从而得到两组双正交向量，这叫做双正交过程。</p><h4 id="具体过程-1"><a href="#具体过程-1" class="headerlink" title="具体过程"></a>具体过程</h4><ol><li>任选两个向量$b_0$和$b_0^<em>$($b_0^</em>$是另一个初始向量，$b_0^* \neq b_0^H$),然后生成</li></ol><script type="math/tex; mode=display">b_1=Ab_0-\alpha_0b_0,\\b_1^*=A'b_0^*-\alpha_0b_0^*,</script><p>其中$\alpha_0$满足双正交条件</p><script type="math/tex; mode=display">\alpha_0=\frac{(Ab_0)'b_0^*}{b_0'b_0^*}=\frac{(A'b_0^*)'b_0}{b_0'b_0^*}</script><ol><li>第二步产生</li></ol><script type="math/tex; mode=display">b_2=Ab_1-\alpha_1b_1-\beta_0b_0,\\b_2^*=A'b_1^*-\alpha_1b_1^*-\beta_0b_0^*,</script><p>其中$\alpha_1$和$\beta_0$满足</p><script type="math/tex; mode=display">\alpha_1=\frac{(A'b_1^*)'b_1}{b_1'b_1^*}=\frac{(Ab_1)'b_1^*}{b_1'b_1^*},\\\beta_0=\frac{(Ab_1^*)'b_0}{b_1'b_0^*}=\frac{(A'b_1^*)'b_0}{b_0'b_0^*}=\frac{b_1' b_1^*}{b_0'b_0^*}.</script><ol><li>继续这一过程，得到如下多项式：<script type="math/tex; mode=display">p_0=1,\\p_1(\mu)=\mu-\alpha_0,\\p_2(\mu)=(\mu-\alpha_1)p_1(\mu)-\beta_0p_0(\mu),\\...\\p_n(\mu)=(\mu-\alpha_{n-1})p_{n-1}(\mu)-\beta_{n-2}p_{n-2}.</script></li></ol><p>为了简便起见, 假设所有的多项式直到 $n$ 次都可由这一过程达到 (没有任何一个 $\beta_i$的值等于零), 则 $p_n$ 是$A$的特征多项式, 其根为 $\mu_i,i=1,2,…,n$.</p><h3 id="3-特征值和特征向量的计算"><a href="#3-特征值和特征向量的计算" class="headerlink" title="3.特征值和特征向量的计算"></a>3.特征值和特征向量的计算</h3><p>我们利用上述特征多项式和双正交序列$\lbrace b_i \rbrace,\lbrace b_i^* \rbrace$来找用这些向量表示的特征向量。</p><p>假设矩阵$A$是<strong>满秩</strong>的，则向量$b_i$可以表示为特征向量的线性组合</p><script type="math/tex; mode=display">b_i=p_i(\mu_1)u_1+p_i(\mu_2)u_2+...+p_i(\mu_n)u_n,</script><p>将$b_i$和$\mu_k^<em>$做内积，其中向量$\mu_k^</em>$和向量$\mu_i$是正交的，可以得到</p><script type="math/tex; mode=display">b_i\mu_k^*=p_i(\mu_k)u_ku_k^*.</script><p><strong>注意</strong>$u_k^* \neq u_k^H$,它们只是分别作为两个同事生成的序列的第$k$次项。反过来，如果将$u_i$用$b_i$表示，则有</p><script type="math/tex; mode=display">u_i=\alpha_{i,0}b_0+\alpha_{i,1}b_1+...+\alpha_{i,n-1}b_{n-1},</script><p>再次使用内积，则有</p><script type="math/tex; mode=display">u_ib_k^*=\alpha_{i,k}b_kb_k^*,\\\alpha_{i,k}=\frac{u_i'b_k^*}{b_k'b_k^*}.</script><p>现在特征向量可展开为</p><script type="math/tex; mode=display">u_i=\frac{b_0}{b_0'b_0^*}+p_1(\mu_i)\frac{b_1}{b_1'b_1^*}+...+p_{n-1}(\mu_i)\frac{b_{n-1}}{b_{n-1}'b_{n-1}^*}.</script><p>由此可类似得出左特征向量</p><script type="math/tex; mode=display">u_i^*=\frac{b_0^*}{b_0'b_0^*}+p_1(\mu_i)\frac{b_1^*}{b_1'b_1^*}+...+p_{n-1}(\mu_i)\frac{b_{n-1}^*}{b_{n-1}'b_{n-1}^*}.</script><p>当矩阵$A$不是满秩，即$m \le n$时，这个展开式仍然是有效的。但很明显这种方法需要重复计算，下面我们直接从矩阵形式来推导。</p><p>首先我们有</p><script type="math/tex; mode=display">T=(B^*)'AB,</script><p>这里</p><script type="math/tex; mode=display">B=[\begin{matrix}b_0&b_1&...&b_{n-1}\end{matrix}],\\B^*=[\begin{matrix}b_0^*&b_1^*&...&b_{n-1}^*\end{matrix}],T=\left[\begin{matrix}\alpha_0&\beta_0\\\beta_0&\alpha_1&\beta_1\\&&\ddots&\ddots&\ddots\\&&&\beta_{n-2}&\alpha_{n-1}&\beta_{n-1}\\&&&&\beta_{n-1}&\alpha_n        \end{matrix}\right],</script><p>由此可得到更有效的特征向量计算方法。通过适当的左乘和右乘非奇异矩阵，方程$Aw=\mu w$化为</p><script type="math/tex; mode=display">(B^*)'AB(B^*)'u=\mu(B^*)'u,</script><p>利用向量$b$的双正交性质</p><script type="math/tex; mode=display">B(B^*)'=I,</script><p>得到</p><script type="math/tex; mode=display">Tv=\mu v,</script><p>其中</p><script type="math/tex; mode=display">v=(B^*)'u,u=Bv.</script><p>即先计算三对角矩阵$T$的特征向量$v$，然后左乘Lanczos向量以得到原矩阵的特征向量。</p><h2 id="low-brightness-总结"><a href="#low-brightness-总结" class="headerlink" title=":low_brightness:总结"></a><span class="github-emoji"><span>🔅</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f505.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>总结</h2><p>Lanczos方法就是将向量$Ab<em>j$投影到前面已有的Lanczos向量所生成的子空间，然后去除$Ab_j$在这个子空间的投影分量，从而得到与这个子空间正交的部分，记为$b</em>{j+1}$。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/11/16/hello-world/"/>
      <url>/2022/11/16/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
